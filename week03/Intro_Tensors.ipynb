{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "Intro_Tensors.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QofHzKCqPFDX"
      },
      "source": [
        "import numpy as np\n",
        "# NEXT LINE ONLY FOR COLAB!\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "# COMMENT OUT THIS LINE FOR COLAB!\n",
        "#%matplotlib notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqI2hSnnPFDj",
        "outputId": "05507bea-e7f1-4e19-d2bc-287c9cd7a6f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d6AgfSRPFDs"
      },
      "source": [
        "## Understanding Tensors and Arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrAp9ys0PFDt",
        "outputId": "adac354a-d914-480f-e439-d9eec3df27e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# A NumPy array is an arbitray dimensional matrix to store numbers in\n",
        "arr = np.reshape(np.arange(9),(3,3))\n",
        "print(arr)\n",
        "print(arr.shape)\n",
        "print(\"------------------\")\n",
        "\n",
        "# Access dimensions of the shape.\n",
        "print(arr.shape[0])\n",
        "print(arr.shape[-1])\n",
        "print(\"------------------\")\n",
        "\n",
        "# Reshaping an array.\n",
        "arr1 = np.reshape(arr, newshape=(9,1))\n",
        "print(arr1)\n",
        "arr2 = np.reshape(arr, newshape=(-1,1)) # The -1 makes numpy infer itself the missing dimension.\n",
        "print(arr2)\n",
        "print(\"------------------\")\n",
        "\n",
        "# Indexing allows you to access specific entries of an array.\n",
        "print(arr[2,1]) # row 2 (third), column 1 (second).\n",
        "print(arr[1,2]) # row 1 (second), column 2 (third).\n",
        "print(\"------------------\")\n",
        "\n",
        "# Slicing allows you to retrieve parts of an array.\n",
        "print(arr[:,1]) # All rows, collumn 1.\n",
        "print(arr[0:2,:]) # Rows from 0 (include) to 2 (exclude), all columns. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 2]\n",
            " [3 4 5]\n",
            " [6 7 8]]\n",
            "(3, 3)\n",
            "------------------\n",
            "3\n",
            "3\n",
            "------------------\n",
            "[[0]\n",
            " [1]\n",
            " [2]\n",
            " [3]\n",
            " [4]\n",
            " [5]\n",
            " [6]\n",
            " [7]\n",
            " [8]]\n",
            "[[0]\n",
            " [1]\n",
            " [2]\n",
            " [3]\n",
            " [4]\n",
            " [5]\n",
            " [6]\n",
            " [7]\n",
            " [8]]\n",
            "------------------\n",
            "7\n",
            "5\n",
            "------------------\n",
            "[1 4 7]\n",
            "[[0 1 2]\n",
            " [3 4 5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSfI-m9BPFD0",
        "outputId": "d88b601e-3beb-4535-ed2b-8725f212914c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Thinking in matrices should be familiar from intro math course. \n",
        "# But the exact same things work in higher dimensions!\n",
        "arr = np.reshape(np.arange(27), (3,3,3))\n",
        "print(arr)\n",
        "print(arr.shape)\n",
        "print(\"------------------\")\n",
        "\n",
        "# Indexing.\n",
        "print(arr[0,1,2])\n",
        "print(\"------------------\")\n",
        "\n",
        "# Slicing.\n",
        "print(arr[:,2,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[ 0  1  2]\n",
            "  [ 3  4  5]\n",
            "  [ 6  7  8]]\n",
            "\n",
            " [[ 9 10 11]\n",
            "  [12 13 14]\n",
            "  [15 16 17]]\n",
            "\n",
            " [[18 19 20]\n",
            "  [21 22 23]\n",
            "  [24 25 26]]]\n",
            "(3, 3, 3)\n",
            "------------------\n",
            "5\n",
            "------------------\n",
            "[[ 6  7  8]\n",
            " [15 16 17]\n",
            " [24 25 26]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHiyio3dPFD5",
        "outputId": "d140c414-586e-4979-9824-6643f67bda30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "# A tensor is kind of like a numpy array.\n",
        "# Strictly spreaking tensors are operations. \n",
        "# You can't simply make a tensor out of a numpy array just like that...\n",
        "tensor = tf.Tensor(arr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d57cad49bc94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Strictly spreaking tensors are operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# You can't simply make a tensor out of a numpy array just like that...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'value_index' and 'dtype'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHrpb2j-pTNh",
        "outputId": "11b19c42-78c8-4683-ce17-83df312c9c15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# but luckily there is an in-built function for that\n",
        "tensor = tf.convert_to_tensor(arr)\n",
        "tensor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3, 3), dtype=int64, numpy=\n",
              "array([[[ 0,  1,  2],\n",
              "        [ 3,  4,  5],\n",
              "        [ 6,  7,  8]],\n",
              "\n",
              "       [[ 9, 10, 11],\n",
              "        [12, 13, 14],\n",
              "        [15, 16, 17]],\n",
              "\n",
              "       [[18, 19, 20],\n",
              "        [21, 22, 23],\n",
              "        [24, 25, 26]]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ4Vs42RPFD-",
        "outputId": "21caa8d4-67ee-42b3-b472-53bab5bf34d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# But if you define a tensor as an operation, the tensor will store the corresponding result of this operation.\n",
        "tensor = tf.multiply(42, arr)\n",
        "print(arr)\n",
        "print(tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[ 0  1  2]\n",
            "  [ 3  4  5]\n",
            "  [ 6  7  8]]\n",
            "\n",
            " [[ 9 10 11]\n",
            "  [12 13 14]\n",
            "  [15 16 17]]\n",
            "\n",
            " [[18 19 20]\n",
            "  [21 22 23]\n",
            "  [24 25 26]]]\n",
            "tf.Tensor(\n",
            "[[[   0   42   84]\n",
            "  [ 126  168  210]\n",
            "  [ 252  294  336]]\n",
            "\n",
            " [[ 378  420  462]\n",
            "  [ 504  546  588]\n",
            "  [ 630  672  714]]\n",
            "\n",
            " [[ 756  798  840]\n",
            "  [ 882  924  966]\n",
            "  [1008 1050 1092]]], shape=(3, 3, 3), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HTBl4kXPFEC",
        "outputId": "4ea93935-7956-40ec-9df9-40ebf085b00b"
      },
      "source": [
        "# If your variable is a tensor you can use all the normal math \n",
        "# operators as '+','-','*','/' and so on.\n",
        "print(tensor/42)\n",
        "print(tf.divide(tensor,42)) # That's the same thing.\n",
        "print(tensor/42+tensor/42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0.  1.  2.]\n",
            "  [ 3.  4.  5.]\n",
            "  [ 6.  7.  8.]]\n",
            "\n",
            " [[ 9. 10. 11.]\n",
            "  [12. 13. 14.]\n",
            "  [15. 16. 17.]]\n",
            "\n",
            " [[18. 19. 20.]\n",
            "  [21. 22. 23.]\n",
            "  [24. 25. 26.]]], shape=(3, 3, 3), dtype=float64)\n",
            "tf.Tensor(\n",
            "[[[ 0.  1.  2.]\n",
            "  [ 3.  4.  5.]\n",
            "  [ 6.  7.  8.]]\n",
            "\n",
            " [[ 9. 10. 11.]\n",
            "  [12. 13. 14.]\n",
            "  [15. 16. 17.]]\n",
            "\n",
            " [[18. 19. 20.]\n",
            "  [21. 22. 23.]\n",
            "  [24. 25. 26.]]], shape=(3, 3, 3), dtype=float64)\n",
            "tf.Tensor(\n",
            "[[[ 0.  2.  4.]\n",
            "  [ 6.  8. 10.]\n",
            "  [12. 14. 16.]]\n",
            "\n",
            " [[18. 20. 22.]\n",
            "  [24. 26. 28.]\n",
            "  [30. 32. 34.]]\n",
            "\n",
            " [[36. 38. 40.]\n",
            "  [42. 44. 46.]\n",
            "  [48. 50. 52.]]], shape=(3, 3, 3), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_gB7m1iPFEG",
        "outputId": "7291a1b3-7bb6-4923-df00-04040be1db03"
      },
      "source": [
        "# You can also easily convert a tensor back to nunpy.\n",
        "print(tensor.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[   0   42   84]\n",
            "  [ 126  168  210]\n",
            "  [ 252  294  336]]\n",
            "\n",
            " [[ 378  420  462]\n",
            "  [ 504  546  588]\n",
            "  [ 630  672  714]]\n",
            "\n",
            " [[ 756  798  840]\n",
            "  [ 882  924  966]\n",
            "  [1008 1050 1092]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U58z_XT_PFEL"
      },
      "source": [
        "## Useful Tensor Operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktZe5BY0PFEL",
        "outputId": "8dd29417-0795-4945-ff99-464185cdb631"
      },
      "source": [
        "# creating a 'scalar' (also called rank-0 tensor\n",
        "#meaning a constant single valued tensor without any axes.\n",
        "scalar = tf.constant(13)\n",
        "print(scalar)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(13, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX2Syn7DPFEP",
        "outputId": "65c2e93d-4c9d-43dc-dc52-7b238cf79ed8"
      },
      "source": [
        "# you can also create tensor vectors from lists with one axia\n",
        "vector = tf.constant([1.0, 2.0, 3.0])\n",
        "print(vector)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCFBnNrdPFET",
        "outputId": "ceee526a-ca93-45c6-e89e-1c8269c07fd7"
      },
      "source": [
        "# or matrices with two axes\n",
        "matrix = tf.constant([[1,2],\n",
        "                      [3,4],\n",
        "                      [5,6]])\n",
        "print(matrix)\n",
        "\n",
        "# of course you can go on creating tensors with an arbitrary number of axes (dimensions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1 2]\n",
            " [3 4]\n",
            " [5 6]], shape=(3, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_MYRtYuPFEY"
      },
      "source": [
        "Indexing of tensors works like standard Python an NumPy indexing rules. You can also use slicing.\n",
        "You can also acces the shape of a tensor and reshape it similar to how you would do it in NumPy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VSfoXLpPFEZ",
        "outputId": "07b0679a-1f7c-4e8e-b0fb-a0162a4645a0"
      },
      "source": [
        "a_tensor = tf.constant([[1,2],\n",
        "                      [3,4],\n",
        "                      [5,6]])\n",
        "\n",
        "# accesing shape\n",
        "print(\"Original shape of tensor:\", a_tensor.shape)\n",
        "# reshaping\n",
        "reshaped_tensor = tf.reshape(a_tensor, [-1])\n",
        "print(\"New shape:\", reshaped_tensor.shape)\n",
        "# you can also expand dimensions\n",
        "print(tf.expand_dims(reshaped_tensor, -1).shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original shape of tensor: (3, 2)\n",
            "New shape: (6,)\n",
            "(6, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6uV6uG6PFEd",
        "outputId": "ac6aae49-b59e-4e62-cfe4-c2edcfb44892"
      },
      "source": [
        "# more useful operations include stacking\n",
        "x = tf.constant([1, 4])\n",
        "y = tf.constant([2, 5])\n",
        "z = tf.constant([3, 6])\n",
        "print(tf.stack([x, y, z]))\n",
        "print(tf.stack([x, y, z], axis=1))\n",
        "\n",
        "# and a lot more...\n",
        "# read the docs!\n",
        "# https://www.tensorflow.org/api_docs/python/tf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1 4]\n",
            " [2 5]\n",
            " [3 6]], shape=(3, 2), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[1 2 3]\n",
            " [4 5 6]], shape=(2, 3), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aocm44HWPFEh",
        "outputId": "95ae3a33-3ea7-4e5a-b68b-3eefd1f05375"
      },
      "source": [
        "# you can easily create tensors containing zeros in any shape\n",
        "print(\"zeros\")\n",
        "print(tf.zeros(1))\n",
        "print(tf.zeros((3,3)))\n",
        "\n",
        "# or ones\n",
        "print(\"\\n ones\")\n",
        "print(tf.ones(1))\n",
        "print(tf.ones((3,3)))\n",
        "\n",
        "# or random values\n",
        "print(\"\\n random\")\n",
        "print(tf.random.normal((3,3), mean=0.0, stddev=1.0))\n",
        "print(tf.random.uniform((3,3)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "zeros\n",
            "tf.Tensor([0.], shape=(1,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]], shape=(3, 3), dtype=float32)\n",
            "\n",
            " ones\n",
            "tf.Tensor([1.], shape=(1,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]], shape=(3, 3), dtype=float32)\n",
            "\n",
            " random\n",
            "tf.Tensor(\n",
            "[[ 9.7113794e-01  2.7382594e-01 -1.5219488e-03]\n",
            " [ 1.7666880e+00  7.5179845e-01  9.0154976e-01]\n",
            " [-1.9685163e-01 -5.6315488e-01 -6.7645156e-01]], shape=(3, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.81329715 0.6354164  0.01760745]\n",
            " [0.8596854  0.05757248 0.07754111]\n",
            " [0.22473991 0.38282108 0.41267502]], shape=(3, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJMC0ZOUAXp0"
      },
      "source": [
        "## Tensorflow Variables\n",
        "\n",
        "Now you have learned how to create constant valued tensors. But if you think ahead, what you will later want to do when implementing a neural network with tensorflow is defining tensors that will be changed a lot throughout running your program. Think back to how a neural network is trained. We first define its weights and then define how these weights are changed so that our network gets better at doing what it is supposed to do.\n",
        "\n",
        "The recommended way to define model parameters, like for example the weights of a MLP, is to use the build in Tensorflow class tf. Variable.\n",
        "\n",
        "A tf.Variable represents a tensor whose value can be changed by running operations on it, modifying its values. Higher level libraries like tf.keras use tf.Variable to store model parameters. \n",
        "\n",
        "Documentation: https://www.tensorflow.org/guide/variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr9B0PctCHK_"
      },
      "source": [
        "# you can create Variables from tensors\n",
        "my_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
        "my_variable = tf.Variable(my_tensor)\n",
        "\n",
        "# Variables can be all kinds of types, just like tensors\n",
        "bool_variable = tf.Variable([False, False, False, True])\n",
        "complex_variable = tf.Variable([5 + 4j, 6 + 1j])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq2PCOyYCkPb",
        "outputId": "4904ab96-4a03-4ed3-8526-df91e72aa7ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a = tf.Variable([2.0, 3.0])\n",
        "print(a)\n",
        "# you can reassign values but it will stick to the original dtype, float32\n",
        "a.assign([1, 2]) \n",
        "print(a)\n",
        "# Not allowed as it resizes the variable: \n",
        "try:\n",
        "  a.assign([1.0, 2.0, 3.0])\n",
        "except Exception as e:\n",
        "  print(f\"{type(e).__name__}: {e}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([2., 3.], dtype=float32)>\n",
            "<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([1., 2.], dtype=float32)>\n",
            "ValueError: Shapes (2,) and (3,) are incompatible\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6ZIe4IfDClN"
      },
      "source": [
        "# you can also name them\n",
        "# and you can decide wether your Variable needs or needs not to be trained\n",
        "step_counter = tf.Variable(1, trainable=False, name=\"step_counter\")\n",
        "# of course, if we mean to define weights, such a Variable should be trainable\n",
        "# this becomes important once we talk about automatic differentiation in trainable (Chapter on Gradient Tapes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWtz-i1RPFEj"
      },
      "source": [
        "## All in all\n",
        "So this was a basic introduction. The get away message is: You can do most of what you do in NumPy in Tensorflow as well. But as tensorflow is specialized in Deep Learning, you will also learn that it offers a lot more. So stay tuned and go on to the next chapters :)"
      ]
    }
  ]
}