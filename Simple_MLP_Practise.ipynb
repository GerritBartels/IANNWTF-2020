{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "Simple_MLP_Practise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anniewit/IANNWTF-2020/blob/main/Simple_MLP_Practise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU1Jsm5I2qiq"
      },
      "source": [
        "import numpy as np\n",
        "# NEXT LINE ONLY FOR COLAB!\n",
        "# %tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "# COMMENT OUT THIS LINE FOR COLAB!\n",
        "# %matplotlib notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9WXpU6Q2qiz",
        "outputId": "8992c7de-b208-4726-b019-86f2946c2e74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV7moAUh2qjC"
      },
      "source": [
        "**Disclaimer:** This Notebook heavily depends on the work of Luke Effenberger who held the course last year. You can find his original material under:\n",
        "https://lukeeffenberger.github.io/IANNWTF-2019/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ri4Q4Vj2qjD"
      },
      "source": [
        "### Create a simple regression dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN3GNCKP2qjG",
        "outputId": "a8dcf9af-bbc2-4036-dbdf-f564b5e85d4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "training_data_xs = np.linspace(-5,5, 20, dtype=np.float32)   ### TODO We need more data so make 200 points instead of 20 out of it \n",
        "def f(x):\n",
        "    return 0.02*(x**3-x**2+2*x)+0.3         # FYI we adapted the function slightly compared to the other notebook\n",
        "training_data_ys = np.array([f(x) for x in training_data_xs], dtype=np.float32)\n",
        "\n",
        "### TODO Make some test data points\n",
        "# They should be on the same line as the train data, but it should ideally be examples that are not included in the training set\n",
        "# you could sample some from the data using np.random.choice()\n",
        "\n",
        "\n",
        "\n",
        "plt.scatter(training_data_xs, training_data_ys, c='red')\n",
        "plt.xlim(-5,5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-5.0, 5.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgRElnR92qjS",
        "outputId": "5e12d4d4-7c9b-4e81-d5b9-7ec17d1ed03d"
      },
      "source": [
        "# First understand the shape that your data has.\n",
        "print(training_data_xs.shape)\n",
        "print(training_data_ys.shape)\n",
        "\n",
        "### TODO Do the same for the test data set\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20,)\n",
            "(20,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6xdCAZ8ikT3"
      },
      "source": [
        "### Convert it to a tf Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IKdkwIaiokw"
      },
      "source": [
        "# It is easiest to use this dataset with TensorFlow by converting\n",
        "# it to a tf.data.Dataset (https://www.tensorflow.org/api_docs/python/tf/data/Dataset).\n",
        "# If, as in our case, you want to convert Numpy Arrays into a dataset\n",
        "# use tf.data.Dataset.from_tensor_slices\n",
        "# reshape the data to convert (1,) into (1,1)\n",
        "# Shuffe the data. If you want, you can also batch your data (e.g batchsize = 20)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzH_TJPA2qjf"
      },
      "source": [
        "### Build a simple network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SchELUJljQE2"
      },
      "source": [
        "The last time we have used the class Linear. This time we want to use already inbuilt layers from **keras!** \n",
        "- Use 2 hidden layers with 256 neurons each and relu activation function. \n",
        "- The output layer has 1 neuron and no activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqFzEsTC2qj3"
      },
      "source": [
        "# We can stack multiple layers onto another to build a deep\n",
        "# neural network. Let' start with a simple MLP with one\n",
        "# hidden layer.\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "\n",
        "# Formally we define another layer. So we have to inherit again.\n",
        "class MLP(Model):\n",
        "    \n",
        "    def __init__(self):\n",
        "        # TODO call the super init again.\n",
        "\n",
        "       # TODO instantiate the layers that our network has.\n",
        "  \n",
        "        \n",
        "    # In the call function we define the forward pass of the network.\n",
        "    def call(self, x):\n",
        "        # TODO \n",
        "        return # TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeVhCkxTltOH"
      },
      "source": [
        "### Define Training and Testing Steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Zt1gj5Z-Yr2"
      },
      "source": [
        "def train_step(model, input, target, loss_function, optimizer):\n",
        "    # compute and apply gradients using gradient Tape\n",
        "     \n",
        "    return loss \n",
        "\n",
        "\n",
        "def test(model, test_data, loss_function):\n",
        "    # test over complete test data\n",
        "    test_loss_aggregator = []\n",
        "\n",
        "    for (input, target) in test_data:\n",
        "        # get a prediction from the model\n",
        "        \n",
        "        # calcuate the loss\n",
        "\n",
        "        # append the loss to the list (you might need to make an array out of it)\n",
        "\n",
        "    test_loss = np.mean(test_loss_aggregator)\n",
        "\n",
        "    return test_loss\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJihal4DIdIA"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "### Hyperparameters\n",
        "num_epochs = 250\n",
        "learning_rate = 0.01\n",
        "running_average_factor = 0.95\n",
        "\n",
        "# TODO Initialize the model.\n",
        "model = \n",
        "\n",
        "# TODO Initialize the loss: Mean Squared Error. Check out 'tf.keras.losses'.\n",
        "mse = \n",
        "\n",
        "# Initialize the optimizer: SGD with default parameters. Check out 'tf.keras.optimizers'\n",
        "optimizer = \n",
        "\n",
        "# Initialize lists for later visualization.\n",
        "train_losses = []\n",
        "\n",
        "test_losses = []\n",
        "\n",
        "#testing once before we begin\n",
        "test_loss = test(model, test_dataset, mse)\n",
        "test_losses.append(test_loss)\n",
        "\n",
        "\n",
        "#check how model performs on train data once before we begin\n",
        "train_loss = test(model, train_dataset, mse)\n",
        "train_losses.append(train_loss)\n",
        "\n",
        "# We train for num_epochs epochs.\n",
        "for epoch in range(num_epochs):\n",
        "    # print('Epoch: __ ' + str(epoch))\n",
        "\n",
        "    # shuffle the data again in each epoch, so that the network cannot learn the order 'by heart'\n",
        "\n",
        "    \n",
        "    #training (and checking in with training)\n",
        "    for (input,target) in train_dataset:\n",
        "      # call the train step to compute the loss\n",
        "\n",
        "    # save the loss by appending it to the list\n",
        "    train_losses.append(running_average)\n",
        "\n",
        "    #testing\n",
        "    test_loss = test(model, test_dataset, mse)\n",
        "    test_losses.append(test_loss)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}